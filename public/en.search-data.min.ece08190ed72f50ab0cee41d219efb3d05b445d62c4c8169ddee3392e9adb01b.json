[{"id":0,"href":"/docs/preliminaries/","title":"Preliminaries","section":"Docs","content":" Preliminaries # Lattices # A lattice is defined as a set of points in n-dimensional space with a periodic structure. A lattice can be represented by a set of linearly independent vectors commonly named the basis of the lattice. If \\(\\bold{b_1}, \u0026hellip;, \\bold{b_n}\\) denote basis vectors we can describe a lattice by: $$\\Lambda(\\bold{b_1}, ..., \\bold{b_n}) = \\{\\sum_{i=1}^{n}x_i\\bold{b_i}: x_i \\in \\mathbb{Z}\\}$$\nIn the rest of this work, we will especially consider q-ary lattices described by a basis \\(\\bold{B} \\in \\mathbb{Z}^{h\\times w}_q\\), in which coefficients are taken modulo q.\nThe Short Vector Problem # The security of lattice based constructions rely on the fact that finding the shortest non-zero vector in a lattice is a hard problem. One usually considers an approximation version of the SVP problem. Given a basis \\(\\bold{B}\\) of a lattice, the approximate SVP problem is the problem of finding a short lattice vector \\(\\bold{v}\\) such that \\(0 \u0026lt; \\lVert \\bold{v} \\rVert \\leq \\gamma\\lambda_1(\\Lambda(\\bold{B}))\\) where \\(\\lambda_1\\) denotes the shortest nonzero vector length and \\(\\gamma\\) is the approximation factor.\nIt is actually believed that no polynomial time algorithm can approximate such a lattice problem within polynomial factors. Furthermore, it is also believed that no polynomial time quantum algorithm can approximate such a lattice problem within polynomial factors.\nLattice reduction algorithms # Lattice reduction algorithms aim to transform a given basis of a lattice into a \u0026ldquo;reduced\u0026rdquo; basis, where the vectors are shorter and closer to being orthogonal. This reduction makes it easier to approximate solutions to hard lattice problems like the Shortest Vector Problem. In short, the quality of a basis can be improved to make the problem easier. The most prominent lattice reduction algorithms include:\nLLL Algorithm (Lenstra–Lenstra–Lovász): it produces a reduced basis in polynomial time, where the vectors are guaranteed to be within a known factor of the shortest vector, but doesn’t necessarily find the shortest vector, BKZ Algorithm (Block Korkine-Zolotarev): the BKZ algorithm is a generalization of the LLL algorithm and provides better reduction at the cost of higher computational complexity. By working in blocks of the lattice and applying LLL reduction to these blocks, BKZ achieves stronger approximations of the shortest vector, though it requires more computational resources. Sieving and Enumeration: algorithms that are designed to give exact solutions to the SVP problem. Security # The foundational belief of security in new lattice-based primitives stems from one key finding. Ajtai’s theorem connected the hardness of certain average-case problems to the difficulty of worst-case problems in lattices. Specifically, Ajtai demonstrated that for the Short Integer Solution (SIS) problem which we will define later, the average-case instances are at least as hard as the worst-case instances of the Shortest Vector Problem (SVP) on lattices. This means that if one could efficiently solve random instances of SIS, then they could also solve the worst-case SVP, a problem believed to be intractable even for quantum computers. Ajtai’s theorem provides a strong security guarantee for lattice-based cryptographic schemes by grounding their security in the hardness of well-studied lattice problems like SVP.\n"},{"id":1,"href":"/docs/lattice-reduction/","title":"Lattice reduction","section":"Docs","content":" Lattice reduction # Useful quantities in lattices # Volume # In each lattice, we can define the volume of the lattice as the volume of its fundamental parallellepiped (the area delimited by the basis vectors). This quantity is an invariant of the lattice and does not depend on the basis chosen. This means that by applying Gram-Schmidt orthogonalization to any basis will give us an orthogonal basis from which we can approximate the volume of the lattice as\n$$ Vol(\\Lambda) = \\prod_{i=0}^{d-1} \\lVert \\bold{b_i}^*\\rVert $$where $\\bold{b_i}*$ are the orthogonal Gram-Schmidt vectors. It is also important to remember that $Vol(\\Lambda) = |Det(\\bold{B})|$, where $\\bold{B}$ is the basis matrix.\nGaussian heuristic # This heuristic predicts that the number of lattice points inside a measurable body $\\mathcal{B}\\subset \\mathbb{R}^d$ is approximately $\\frac{Vol(\\mathcal{B})}{Vol(\\Lambda)}$ meaning that applied to an euclidean d-ball we get\n$$ \\lambda_1(\\Lambda) \\approx \\sqrt{\\frac{d}{2\\pi e}} Vol(\\Lambda)^{\\frac{1}{d}} = \\sqrt{\\frac{d}{2\\pi e}} |Det(\\Lambda)|^{\\frac{1}{d}}$$which is an approximation of the length of the smallest vector in the lattice.\nLLL algorithm and Geometric Series Assumption (GSA) # The Lenstra-Lenstra-Lovász (LLL) algorithm is an efficient polynomial-time algorithm in lattice theory that finds a \u0026ldquo;nearly orthogonal\u0026rdquo; basis for a given lattice. It aims to transform any arbitrary basis of a lattice into a reduced basis where the basis vectors are short and close to orthogonal following two conditions: 1\\leq j \u0026lt; i \\leq d \\quad \\Rightarrow | \\frac{\\langle \\boldsymbol{b}_i, \\boldsymbol{b}_j^* \\rangle}{\\langle \\boldsymbol{b}_j^, \\boldsymbol{b}_j^ \\rangle}| \\leq \\frac{1}{2}\nSize reduction: $$1 \\leq j \u003c i \\leq n\\colon \\left|\\mu_{i,j}\\right|\\leq 0.5 \\text{ for } \\mu_{i,j} =\\frac{\\langle\\mathbf{b}_i,\\mathbf{b}^*_j\\rangle}{\\langle\\mathbf{b}^*_j,\\mathbf{b}^*_j\\rangle}$$ Lovász condition: For $k=2,\u0026hellip;,n$ $$\\delta \\lVert \\bold{b}^*_{k-1} \\rVert^2 \\leq \\lVert \\bold{b}^*_{k} \\rVert$$ "},{"id":2,"href":"/docs/cost-models/","title":"Cost Models","section":"Docs","content":" Cost Models # "},{"id":3,"href":"/docs/sis/","title":"SIS","section":"Docs","content":" Short Integer Solution problem (SIS) # Let us look at two different ways to define q-ary lattices. From \\(\\bold{A} \\in \\mathbb{Z}_q^{h\\times w}\\)\n$$\\Lambda_q(\\bold{A^T}) = \\{\\bold{y} \\in \\mathbb{Z}^w : \\bold{y} = \\bold{A}^T\\bold{s} \\text{ mod q }\\text{ for some } \\bold{s} \\in \\mathbb{Z}^h\\}$$$$\\Lambda^T_q(\\bold{A}) = \\{\\bold{y} \\in \\mathbb{Z}^w : \\bold{A}\\bold{y} = \\bold{0} \\text{ mod q }\\}$$The first lattice is generally called the primal problem and relates to the LWE problem since finding a short vector in \\(\\Lambda_q(\\bold{A^T})\\) corresponds to solving the LWE problem. The second lattice is generally called the dual problem and relates to the SIS problem since finding a short vector in \\(\\Lambda^T_q(\\bold{A})\\) corresponds to solving the SIS problem.\nFormal definition # We define \\(SIS(h, q, w, \\beta)\\) as follows:\nGiven \\(\\bold{A} \\in \\mathbb{Z}_q^{h\\times w}\\) find the short vector \\(\\bold{s} \\in \\mathbb{Z}^w\\) where \\(0 \u0026lt; \\lVert s \\rVert_p \\leq \\beta\\).\nWe can note that the problem becomes trivial as soon as \\(\\beta \\geq q\\), no matter the norm used.\nEstimating SIS hardness # Estimating the hardness of an SIS instance is done via estimating the number of operations required to run lattice reductions attacks on the related SVP problem. This concretely means that we need to know:\nHow small we expect the shortest vector to be in our SVP problem. How small we expect vectors to be after lattice reduction. How to cost lattice reduction. We will mostly focus on BKZ 2.0 as a reduction algorithm and we will present how we estimate all parts of the attack.\nExpected size of small vectors # Given a random matrix \\(\\bold{A} \\in \\mathbb{Z}_q^{h\\times w}\\)\n"},{"id":4,"href":"/docs/sis/module-sis/","title":"Module Sis","section":"SIS","content":" Module-SIS # "},{"id":5,"href":"/docs/sis/ring-sis/","title":"Ring Sis","section":"SIS","content":" Ring-SIS # "}]